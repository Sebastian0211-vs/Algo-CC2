# â±ï¸ Complexity Cheat Sheet â€“ Analyse de complexitÃ© (Big-O)

Ce fichier sert de **rÃ©fÃ©rence rapide** pour analyser la **complexitÃ© temporelle et spatiale**
des algorithmes classiques.

Objectif :

> reconnaÃ®tre rapidement un **ordre de grandeur**,
> le **justifier**,
> et Ã©viter les erreurs classiques en examen.

---

## ğŸ”¹ Rappels essentiels

La notation **Big-O** dÃ©crit :

* le **pire cas**,
* le comportement quand `n â†’ âˆ`,
* en ignorant les constantes.

Ordre de croissance (du meilleur au pire) :

```
O(1) < O(log n) < O(n) < O(n log n) < O(nÂ²) < O(2â¿) < O(n!)
```

---

## ğŸ” Boucles classiques

### Boucle simple

```python
for i in range(n):
    ...
```

â¡ **O(n)**

---

### Boucles imbriquÃ©es indÃ©pendantes

```python
for i in range(n):
    for j in range(n):
        ...
```

â¡ **O(nÂ²)**

---

### Boucles dÃ©pendantes

```python
for i in range(n):
    for j in range(i):
        ...
```

â¡ **O(nÂ²)**
(moyenne â‰ˆ nÂ²/2 â†’ Big-O reste nÂ²)

---

### Boucle logarithmique

```python
i = n
while i > 1:
    i //= 2
```

â¡ **O(log n)**

---

## ğŸ” Recherche

| MÃ©thode                             | ComplexitÃ©      |
| ----------------------------------- | --------------- |
| Recherche linÃ©aire                  | O(n)            |
| Recherche binaire                   | O(log n)        |
| Recherche avec hash (`set`, `dict`) | O(1) en moyenne |

---

## ğŸŒ Graphes

Soit :

* `V` = nombre de sommets
* `E` = nombre dâ€™arÃªtes

### BFS / DFS

â¡ **O(V + E)**

Pourquoi :

* chaque sommet est visitÃ© une fois,
* chaque arÃªte est explorÃ©e au plus une fois.

---

### Dijkstra (heap)

â¡ **O((V + E) log V)**
(souvent notÃ© **O(E log V)**)

---

### Bellman-Ford

â¡ **O(V Â· E)**

---

### Floyd-Warshall

â¡ **O(VÂ³)**

---

### Topological Sort

â¡ **O(V + E)**

---

## ğŸŒ² Arbres

### Parcours (DFS/BFS)

â¡ **O(n)**

---

### DiamÃ¨tre dâ€™un arbre (double BFS)

â¡ **O(n)**

---

### LCA (Binary Lifting)

| Phase         | ComplexitÃ© |
| ------------- | ---------- |
| PrÃ©traitement | O(n log n) |
| RequÃªte       | O(log n)   |

---

### Union-Find (DSU)

| OpÃ©ration    | ComplexitÃ©             |
| ------------ | ---------------------- |
| find / union | **O(Î±(n))** â‰ˆ constant |

(Î± = fonction dâ€™Ackermann inverse)

---

## âš¡ Greedy

Souvent dominÃ© par un tri :

â¡ **O(n log n)**

Exemples :

* Interval Scheduling
* Kruskal
* Goose Game

---

## ğŸ§® Programmation Dynamique (DP)

### DP 1D

```python
dp = [0] * n
```

â¡ **Temps : O(n)**
â¡ **MÃ©moire : O(n)**

---

### DP 2D

```python
dp = [[0]*m for _ in range(n)]
```

â¡ **Temps : O(nÂ·m)**
â¡ **MÃ©moire : O(nÂ·m)**

---

### DP avec Ã©tats compressÃ©s

â¡ **O(n Â· 2â¿)**
(utilisÃ© quand `n â‰¤ 20`)

---

## ğŸ” Backtracking

ComplexitÃ© souvent **exponentielle**.

| ProblÃ¨me                     | ComplexitÃ©        |
| ---------------------------- | ----------------- |
| GÃ©nÃ©ration de sous-ensembles | O(2â¿)             |
| Permutations                 | O(n!)             |
| Combinaisons                 | dÃ©pend du pruning |

âš ï¸ Le **pruning** rÃ©duit le temps **en pratique**,
mais pas le pire cas thÃ©orique.

---

## ğŸ® Jeux & Minimax

### Minimax naÃ¯f

â¡ **O(báµˆ)**

* `b` = facteur de branchement
* `d` = profondeur

---

### Alpha-Beta Pruning (idÃ©al)

â¡ **O(b^(d/2))**

Permet de **doubler la profondeur explorÃ©e**.

---

## ğŸ§  Astuces dâ€™examen

* Un `set` ou `dict` â‡’ souvent **O(1)** attendu
* BFS sur graphe non pondÃ©rÃ© â‡’ **O(V + E)** (pas Dijkstra)
* Tri presque toujours â‡’ **O(n log n)**
* DP = **taille du tableau**
* Backtracking = **exponentiel par dÃ©faut**

---

## âŒ Erreurs frÃ©quentes

* Dire `O(n)` au lieu de `O(V + E)`
* Oublier le `log n` du heap
* Sous-estimer un backtracking
* Compter des constantes inutiles

---

# Conclusion

Savoir **coder** un algorithme est important.
Savoir **justifier sa complexitÃ©** est indispensable.

Ce fichier doit te permettre de :

* reconnaÃ®tre un schÃ©ma,
* annoncer un Big-O crÃ©dible,
* et le dÃ©fendre clairement Ã  lâ€™Ã©crit comme Ã  lâ€™oral.

